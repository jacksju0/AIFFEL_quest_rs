{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51ad27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch and torchvision\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# GPU 확인\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "#!wget \"http://vision.stanford.edu/aditya86/ImageNetDogs/images.tar\" -P ./data\n",
    "#!tar -xf ./data/images.tar -C ./data/\n",
    "\n",
    "\n",
    "import random\n",
    "# 1) 시드 고정\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de15014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "dataset_dir = \"./data/Images/\"\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # 크기 통일\n",
    "    transforms.ToTensor(),  # Tensor 변환\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # 정규화 추가\n",
    "])\n",
    "full_dataset = ImageFolder(root=dataset_dir, transform=transform)\n",
    "\n",
    "total_size = len(full_dataset)\n",
    "train_size = int(0.583 * total_size)  # 약 12,000개\n",
    "test_size = total_size - train_size   # 약 8,580개\n",
    "ds_train, ds_test = random_split(full_dataset, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287e54be",
   "metadata": {},
   "source": [
    "## CUTMIX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c699f374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def cutmix(images, labels, p=0.5, num_classes=120, alpha=1.0):\n",
    "    \"\"\"\n",
    "    images: (B, C, H, W)  # CPU 텐서 (DataLoader에서 나온 그대로)\n",
    "    labels: (B,)          # 정수 클래스 인덱스 텐서\n",
    "    p: CutMix 적용 확률\n",
    "    num_classes: 클래스 수\n",
    "    alpha: Beta 분포 파라미터 (lam 샘플링용)\n",
    "\n",
    "    반환:\n",
    "      mixed_images: (B, C, H, W)\n",
    "      mixed_labels: (B, num_classes)  # 항상 soft label(one-hot 혼합)\n",
    "    \"\"\"\n",
    "    device = images.device\n",
    "    B, C, H, W = images.shape\n",
    "\n",
    "    # 정수 라벨 보장\n",
    "    labels = labels.to(torch.long)\n",
    "\n",
    "    # 기본 one-hot 라벨\n",
    "    labels_onehot = F.one_hot(labels, num_classes=num_classes).float()\n",
    "\n",
    "    # 기본값: 아무것도 안 섞은 상태\n",
    "    mixed_images = images.clone()\n",
    "    mixed_labels = labels_onehot.clone()\n",
    "\n",
    "    # CutMix 적용할 샘플 마스크\n",
    "    mask = torch.rand(B, device=device) < p\n",
    "    if mask.sum() == 0:\n",
    "        # 이번 배치에서는 CutMix 안 함\n",
    "        return mixed_images, mixed_labels\n",
    "\n",
    "    # 섞을 대상 인덱스\n",
    "    idx = torch.nonzero(mask).squeeze(1)      # (K,)\n",
    "    perm = torch.randperm(B, device=device)   # 전체 배치에서 섞을 대상\n",
    "\n",
    "    # lam 샘플링 (하나로 공유해도 되고, 필요하면 per-sample로 바꿀 수도 있음)\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "    # 랜덤 박스 좌표 계산\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w = int(W * cut_rat)\n",
    "    cut_h = int(H * cut_rat)\n",
    "\n",
    "    cx = np.random.randint(W)\n",
    "    cy = np.random.randint(H)\n",
    "\n",
    "    x1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    x2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    y1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    y2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "\n",
    "    # 이미지 섞기 (mask가 True인 샘플에만 적용)\n",
    "    mixed_images[idx, :, y1:y2, x1:x2] = images[perm[idx], :, y1:y2, x1:x2]\n",
    "\n",
    "    # 실제 영역 비율로 lam 보정\n",
    "    lam_area = 1.0 - ((x2 - x1) * (y2 - y1) / (W * H))\n",
    "\n",
    "    # 라벨 섞기\n",
    "    mixed_labels[idx] = (\n",
    "        lam_area * labels_onehot[idx]\n",
    "        + (1.0 - lam_area) * labels_onehot[perm[idx]]\n",
    "    )\n",
    "\n",
    "    return mixed_images, mixed_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd48cb0",
   "metadata": {},
   "source": [
    "## MIXUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f07a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def mixup(images, labels, p=0.5, num_classes=120, alpha=1.0):\n",
    "    \"\"\"\n",
    "    images: (B, C, H, W)  # DataLoader에서 나온 배치 (CPU)\n",
    "    labels: (B,)          # 정수 클래스 인덱스 (0 ~ num_classes-1)\n",
    "    p: Mixup 적용 확률\n",
    "    num_classes: 클래스 개수\n",
    "    alpha: Beta 분포 파라미터 (lam 샘플링용)\n",
    "\n",
    "    반환:\n",
    "      mixed_images: (B, C, H, W)\n",
    "      mixed_labels: (B, num_classes)  # 항상 soft label(one-hot 혼합)\n",
    "    \"\"\"\n",
    "    device = images.device\n",
    "    B = images.size(0)\n",
    "\n",
    "    # 정수 라벨 보장\n",
    "    labels = labels.to(torch.long)\n",
    "\n",
    "    # 기본 one-hot 라벨\n",
    "    labels_onehot = F.one_hot(labels, num_classes=num_classes).float()\n",
    "\n",
    "    # 기본값: Mixup 안 한 상태\n",
    "    mixed_images = images.clone()\n",
    "    mixed_labels = labels_onehot.clone()\n",
    "\n",
    "    # Mixup 적용 여부\n",
    "    if np.random.rand() >= p:\n",
    "        # 이번 배치에서는 Mixup 생략\n",
    "        return mixed_images, mixed_labels\n",
    "\n",
    "    # lam 샘플링\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "\n",
    "    # 섞을 인덱스\n",
    "    index = torch.randperm(B, device=device)\n",
    "\n",
    "    # 이미지 섞기\n",
    "    mixed_images = lam * images + (1.0 - lam) * images[index]\n",
    "\n",
    "    # 라벨 섞기\n",
    "    mixed_labels = lam * labels_onehot + (1.0 - lam) * labels_onehot[index]\n",
    "\n",
    "    return mixed_images, mixed_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab51add9",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d91fff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def augment(image, label):\n",
    "    transform = transforms.RandomApply([\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.ColorJitter(brightness=0.2),\n",
    "        transforms.Lambda(lambda img: torch.clamp(img, 0, 1))  # 값 클리핑\n",
    "    ],p=0.5)\n",
    "    return transform(image), label\n",
    "\n",
    "# 원-핫 인코딩\n",
    "def onehot(labels, num_classes=120):\n",
    "    # labels: 스칼라 int / 리스트 / (B,) 텐서 모두 지원\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        labels = labels.to(torch.long)\n",
    "    else:\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "    return F.one_hot(labels, num_classes=num_classes).float()\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class WrappedDataset(Dataset):\n",
    "    def __init__(self, base_dataset, is_test=False, with_aug=False):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.is_test = is_test\n",
    "        self.with_aug = with_aug\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img, lbl = self.base_dataset[idx]\n",
    "\n",
    "        # 기존에 쓰던 함수 재사용 (크기조정 + 정규화용)\n",
    "        #img, lbl = normalize_and_resize_img(img, lbl)\n",
    "\n",
    "        # train이고, with_aug=True일 때만 증강\n",
    "        if (not self.is_test) and self.with_aug:\n",
    "            # augment가 (img, lbl) -> (img, lbl) 이라고 가정\n",
    "            img, lbl = augment(img, lbl)\n",
    "\n",
    "        return img, lbl\n",
    "\n",
    "class OneHotCollator:\n",
    "    def __init__(self, num_classes=120):\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        # batch: [(img, lbl), (img, lbl), ...]\n",
    "        imgs, labels = zip(*batch)  # 튜플 목록 분리\n",
    "        imgs = torch.stack(imgs)    # (B, C, H, W)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)  # (B,)\n",
    "\n",
    "        labels = onehot(labels, num_classes=self.num_classes)  # (B, num_classes)\n",
    "        return imgs, labels\n",
    "    \n",
    "class CutMixCollator:\n",
    "    def __init__(self, num_classes=120, p=0.5):\n",
    "        self.num_classes = num_classes\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        imgs, labels = zip(*batch)\n",
    "        imgs = torch.stack(imgs)                         # (B, C, H, W)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)  # (B,)\n",
    "\n",
    "        imgs, labels = cutmix(\n",
    "            imgs,\n",
    "            labels,\n",
    "            p=self.p,\n",
    "            num_classes=self.num_classes,\n",
    "        )\n",
    "        # labels: (B, num_classes) soft label\n",
    "        return imgs, labels\n",
    "\n",
    "    \n",
    "class MixupCollator:\n",
    "    def __init__(self, num_classes=120, p=0.5):\n",
    "        self.num_classes = num_classes\n",
    "        self.p = p\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        imgs, labels = zip(*batch)\n",
    "        imgs = torch.stack(imgs)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        #labels = onehot(labels, num_classes=self.num_classes)\n",
    "\n",
    "        imgs, labels = mixup(imgs, labels, p=self.p)\n",
    "        return imgs, labels\n",
    "    \n",
    "# 데이터셋 적용\n",
    "def apply_normalize_on_dataset(\n",
    "    dataset,\n",
    "    is_test=False,\n",
    "    batch_size=16,\n",
    "    with_aug=False,\n",
    "    with_cutmix=False,\n",
    "    with_mixup=False,\n",
    "    num_classes=120,\n",
    "):\n",
    "    # 1) Dataset 래핑 (normalize + aug 포함)\n",
    "    wrapped_ds = WrappedDataset(dataset, is_test=is_test, with_aug=with_aug)\n",
    "\n",
    "    # 2) collate_fn 선택\n",
    "    if is_test:\n",
    "        # test에서는 기본 collate 사용 (그냥 int 라벨 유지)\n",
    "        collate_fn = None\n",
    "        shuffle = False\n",
    "    else:\n",
    "        shuffle = True\n",
    "        if with_cutmix:\n",
    "            collate_fn = CutMixCollator(num_classes=num_classes, p=0.5)\n",
    "        elif with_mixup:\n",
    "            collate_fn = MixupCollator(num_classes=num_classes, p=0.5)\n",
    "        else:\n",
    "            collate_fn = OneHotCollator(num_classes=num_classes)\n",
    "\n",
    "    # 3) DataLoader 생성\n",
    "    dataloader = DataLoader(\n",
    "        wrapped_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=shuffle,\n",
    "        num_workers=0,\n",
    "        pin_memory=True,\n",
    "        collate_fn=collate_fn,\n",
    "    )\n",
    "\n",
    "    return dataloader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b07514",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdf5a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train(model, train_loader, test_loader, _criterion , _optimizer ,epochs):\n",
    "    model.to(device)\n",
    "    history = {'train_losses':[],\n",
    "               'train_accuracy':[],\n",
    "               'val_losses':[],\n",
    "               'val_accuracy':[]\n",
    "               }\n",
    "    criterion = _criterion\n",
    "    optimizer = _optimizer\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        running_loss=0.0\n",
    "\n",
    "        for images, labels in train_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "\n",
    "            is_soft = (labels.ndim == 2) and labels.dtype.is_floating_point\n",
    "            if is_soft:\n",
    "                # labels: (B, num_classes) 소프트 레이블\n",
    "                loss = criterion(outputs, labels.float())\n",
    "            else:\n",
    "                # labels: (B,) 정수 레이블\n",
    "                loss = criterion(outputs, labels.long())\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            _, predicted = outputs.max(1)  # (B,)\n",
    "            if is_soft:\n",
    "                # soft label일 때는 가장 확률 높은 클래스를 타겟으로 봄\n",
    "                target_for_acc = labels.argmax(dim=1)  # (B,)\n",
    "            else:\n",
    "                target_for_acc = labels  # 이미 (B,)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            #correct += predicted.eq(labels).sum().item()\n",
    "            correct += predicted.eq(target_for_acc).sum().item()\n",
    "\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "\n",
    "        train_acc = 100. * correct / total\n",
    "        #print(f\"Epoch [{epoch+1}/{epochs}], Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        running_loss=0.0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                \n",
    "                _, predicted = outputs.max(1)\n",
    "                total += labels.size(0)\n",
    "                correct += predicted.eq(labels).sum().item()\n",
    "        val_loss = running_loss / len(test_loader)\n",
    "        val_acc = 100. * correct / total\n",
    "\n",
    "        history['train_losses'].append(train_loss)\n",
    "        history['train_accuracy'].append(train_acc)\n",
    "        history['val_losses'].append(val_loss)\n",
    "        history['val_accuracy'].append(val_acc)\n",
    "\n",
    "        print(f\"[Epoch {epoch + 1:3}/{epochs}] \\\n",
    "Train Loss: {train_loss:.5f} | Train Acc.: {train_acc:3.2f}% | \\\n",
    "Valid Loss: {val_loss  :.5f} | Valid Acc.: {val_acc  :3.2f}%\")\n",
    "        \n",
    "        #print(f\"Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d095509",
   "metadata": {},
   "source": [
    "## TrainLoader 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e955694c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader1 =apply_normalize_on_dataset(ds_train, is_test=False, batch_size=16, with_aug=False, with_cutmix=False, with_mixup=False)\n",
    "trainloader2 =apply_normalize_on_dataset(ds_train, is_test=False, batch_size=16, with_aug=True,  with_cutmix=False, with_mixup=False)\n",
    "trainloader3 =apply_normalize_on_dataset(ds_train, is_test=False, batch_size=16, with_aug=False, with_cutmix=True,  with_mixup=False)\n",
    "trainloader4 =apply_normalize_on_dataset(ds_train, is_test=False, batch_size=16, with_aug=False, with_cutmix=False, with_mixup=True)\n",
    "\n",
    "testloader   =apply_normalize_on_dataset(ds_test , is_test=True , batch_size=16, with_aug=False, with_cutmix=False, with_mixup=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cebe9c1",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a1b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import gc\n",
    "\n",
    "num_classes = 120\n",
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n",
    "\n",
    "EPOCH = 20\n",
    "trainloader1 =apply_normalize_on_dataset(ds_train, is_test=False, batch_size=16, with_aug=False, with_cutmix=False, with_mixup=False)\n",
    "testloader   =apply_normalize_on_dataset(ds_test , is_test=True , batch_size=16, with_aug=False, with_cutmix=False, with_mixup=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.parameters(), lr=0.001)\n",
    "history_resnet50_tl1 = train(resnet50, trainloader1, testloader,criterion,optimizer, EPOCH)\n",
    "\n",
    "del resnet50, trainloader1, testloader\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()    # 3) PyTorch CUDA 캐시 비우기\n",
    "    torch.cuda.reset_peak_memory_stats()    # (선택) 통계 리셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d287facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import gc\n",
    "\n",
    "num_classes = 120\n",
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n",
    "\n",
    "EPOCH = 20\n",
    "trainloader2 =apply_normalize_on_dataset(ds_train, is_test=False, batch_size=16, with_aug=True,  with_cutmix=False, with_mixup=False)\n",
    "testloader   =apply_normalize_on_dataset(ds_test , is_test=True , batch_size=16, with_aug=False, with_cutmix=False, with_mixup=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.parameters(), lr=0.001)\n",
    "history_resnet50_tl2 = train(resnet50, trainloader2, testloader,criterion,optimizer, EPOCH)\n",
    "\n",
    "del resnet50, trainloader2, testloader\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()    # 3) PyTorch CUDA 캐시 비우기\n",
    "    torch.cuda.reset_peak_memory_stats()    # (선택) 통계 리셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bc0cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import gc\n",
    "\n",
    "num_classes = 120\n",
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n",
    "\n",
    "EPOCH = 20\n",
    "trainloader3 =apply_normalize_on_dataset(ds_train, is_test=False, batch_size=16, with_aug=False, with_cutmix=True,  with_mixup=False)\n",
    "testloader   =apply_normalize_on_dataset(ds_test , is_test=True , batch_size=16, with_aug=False, with_cutmix=False, with_mixup=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.parameters(), lr=0.001)\n",
    "history_resnet50_tl3 = train(resnet50, trainloader3, testloader,criterion,optimizer, EPOCH)\n",
    "\n",
    "del resnet50, trainloader3, testloader\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()    # 3) PyTorch CUDA 캐시 비우기\n",
    "    torch.cuda.reset_peak_memory_stats()    # (선택) 통계 리셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f864a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import gc\n",
    "\n",
    "num_classes = 120\n",
    "resnet50 = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V1)\n",
    "resnet50.fc = nn.Linear(resnet50.fc.in_features, num_classes)\n",
    "\n",
    "EPOCH = 20\n",
    "trainloader4 =apply_normalize_on_dataset(ds_train, is_test=False, batch_size=16, with_aug=False, with_cutmix=False, with_mixup=True)\n",
    "testloader   =apply_normalize_on_dataset(ds_test , is_test=True , batch_size=16, with_aug=False, with_cutmix=False, with_mixup=False)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(resnet50.parameters(), lr=0.001)\n",
    "history_resnet50_tl4 = train(resnet50, trainloader4, testloader,criterion,optimizer, EPOCH)\n",
    "\n",
    "del resnet50, trainloader4, testloader\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()    # 3) PyTorch CUDA 캐시 비우기\n",
    "    torch.cuda.reset_peak_memory_stats()    # (선택) 통계 리셋"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e1715e",
   "metadata": {},
   "source": [
    "## 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9979cdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve- 훈련 손실(training loss) 비교\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "plot_name = ['No aug', '50% basic aug',\n",
    "               '50% CutMIX', '50% MIXUP']\n",
    "\n",
    "history=[]\n",
    "history.append(history_resnet50_tl1)\n",
    "history.append(history_resnet50_tl2)\n",
    "history.append(history_resnet50_tl3)\n",
    "history.append(history_resnet50_tl4)\n",
    "\n",
    "color=['red','blue','green','black']\n",
    "\n",
    "fig,axs = plt.subplots(2,2,figsize=(12, 8))\n",
    "\n",
    "for i in range(len(plot_name)):\n",
    "\n",
    "    axs[0,0].plot(history[i]['train_losses'], color=color[i], label=plot_name[i])\n",
    "    axs[0,0].set_title('Training Loss')\n",
    "    axs[0,0].set_ylabel('Loss')\n",
    "    axs[0,0].set_xlabel('Epoch')\n",
    "    axs[0,0].grid(which='both', axis='both', linestyle='--')\n",
    "    axs[0,0].legend(loc='upper right')\n",
    "\n",
    "    axs[0,1].plot(history[i]['val_losses'], color=color[i], label=plot_name[i])\n",
    "    axs[0,1].set_title('Validation Loss')\n",
    "    axs[0,1].set_ylabel('Loss')\n",
    "    axs[0,1].set_xlabel('Epoch')\n",
    "    axs[0,1].grid(which='both', axis='both', linestyle='--')\n",
    "    axs[0,1].set_ylim(0.5,0.8)\n",
    "\n",
    "    axs[1,0].plot(history[i]['train_accuracy'], color=color[i], label=plot_name[i])\n",
    "    axs[1,0].set_title('Train Accuracy')\n",
    "    axs[1,0].set_ylabel('Accuracy (%)')\n",
    "    axs[1,0].set_xlabel('Epoch')\n",
    "    axs[1,0].grid(which='both', axis='both', linestyle='--')\n",
    "\n",
    "    axs[1,1].plot(history[i]['val_accuracy'], color=color[i], label=plot_name[i])\n",
    "    axs[1,1].set_title('Validation Accuracy')\n",
    "    axs[1,1].set_ylabel('Accuracy (%)')\n",
    "    axs[1,1].set_xlabel('Epoch')\n",
    "    axs[1,1].grid(which='both', axis='both', linestyle='--')\n",
    "    axs[1,1].set_ylim(80,85)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d0a94c",
   "metadata": {},
   "source": [
    "## 결론 및 고찰\n",
    "\n",
    "<img src='rubric.png' width='500'><br>\n",
    "\n",
    "<img src='output.png' width='700'>\n",
    "\n",
    "**1. < basic augmentation >**\n",
    "     - RandomHorizontalFlip(p=0.5)\n",
    "     - ColorJitter(brightness=0.2)\n",
    "\n",
    "**2. 각 augmentation은 모두 50%의 확률로 적용하여 실험 진행**\n",
    "\n",
    "**3. < 20 epoch Validation 결과 >**\n",
    "|Augmentation|Loss|Accuracy(%)|\n",
    "|:--|:--:|:--:|\n",
    "|No Aug|0.54534|84.00|\n",
    "|50% basic Aug|0.57538|83.45|\n",
    "|50% CutMix|0.56502|84.16|\n",
    "|50% MixUp|0.60617|84.09|\n",
    "\n",
    "**4. Validation Loss 기준 분석**\n",
    "- (20 Epoch)성능 순서: No Aug >> CutMix > basic Aug. > MixUp\n",
    "- Augmentation을 50% 씩 적용해서 아직 학습이 덜 된것으로 보인다. Epoch을 늘여서 볼 필요 있음.\n",
    "     - Augmentation을 적용하면 그만큼 다양한 분포를 학습하므로 상대적으로 학습이 더디다.\n",
    "     - train loss를 보더라도 아직 학습 할 수 있는 여건이 충분이 남은 것으로 보인다.\n",
    "- CrossEntropyLoss를 사용했는데, log로 인해 정답은 맞추었지만 loss는 매우 크게 차이가 날 수 있다.\n",
    "     - 소수의 강하게 틀린 샘플이 loss에 크게 반영 될 수도 있다.\n",
    "     - 따라서, Loss만으로 성능을 확신하는건 맞지 않다.\n",
    "     - 특히, CutMix나 MixUp은 soft label을 사용하여 CrossEntropyLoss가 조금 더 크게 나오는 특성이 있는 것으로 보인다.\n",
    "\n",
    "**5. Validation Accuracy 기준 분석**\n",
    "- (20 Epoch)성능 순서: 50% CutMix ≈ 50% MixUp ≈ No Aug. >> 50% basic Aug.\n",
    "- 마찬가지로, Augmentation을 50% 씩 적용해서 아직 학습이 덜 된것으로 보인다. Epoch을 늘여서 볼 필요 있음.\n",
    "     - train accuracy를 보더라도 아직 학습 할 수 있는 여건이 충분이 남은 것으로 보인다.\n",
    "- Validation Loss에서 언급했듯이 Loss성능은 좋지 않게 나왔더라도 Validation Accuracy는 좋게 나올 수 있음을 확인 할 수 있다.\n",
    "- basic augmentation 만을 50% 적용한 것이 성능이 가장 좋지 않게 나오고 있다. Epoch을 늘려봐야 확신 할 수 있겠지만, 이런 경향이 이어진다면, horizontalFlip과 Brightness 만으로는 주어진 데이터에 적합하지 않다고 생각할 수도 있겠다.\n",
    "\n",
    "**6. Train Loss/Accuracy 기준 분석**\n",
    "- basic arg.를 적용한 것에 비해 CutMix와 MixUp을 적용한 것이 loss가 천천히 떨어짐을 확인할 수 있다.\n",
    "     - CutMix와 MixUp이 보다 많은 변화와 노이즈를 포함하며, soft label을 사용하기 때문으로 보인다.\n",
    "- 하지만, Accuracy는 basic aug를 포함 비슷하게 올라가고 있는 것으로 보아 Epoch이 길어지면 basic augs는 상대적으로 빨리 수렴하고 CutMix와 MixUp은 더 나은 accuracy에서 수렴할 것으로 기대된다.\n",
    "- 상대적으로 No aug는 모델이 빠르게 학습 데이터의 패턴을 익혀서, 빠르게 수렴하고 있는 것으로 보인다. Epoch를 늘이면 Validation에서 일반화 성능이 상대적으로 떨어지는 것을 볼 수 있을 것 같다.\n",
    "\n",
    "**7. 종합 분석**\n",
    "- 아직 학습할 수 있는 여지가 많이 남아있다. 하지만, 20Epoch까지의 경향과 augmentation들의 특성으로 미루어 보아, Epoch를 늘려서 보았을 때, CutMix ≈ MixUp > basic Aug > No Aug 순서로 Validation accuracy가 나타날 것 같다.\n",
    "     - augmentation 이 적용되면 학습은 길어지지만 성능은 올라간다.\n",
    "     - CutMix와 MixUp은 상대적으로 많은 변화를 포함하는 편이며, soft label을 사용하여 CE loss는 높게 나오지만 Accuracy는 좋게(높게) 나오는 경향이 있음\n",
    "     - MixUp은 결정 경계가 완만하게 바뀌는 효과로 accuracy는 높이지만, output의 확률 분포가 완만해져서 CrossEntropyLoss는 크게 보일 수 있다.\n",
    "     - CutMix는 일부 영역을 잘라서 붙이므로 MixUp 보다는 결정 경계가 덜 완만할 것으로 생각됨. 하지만, MixUp과 마찬가지로 accuracy는 높이지만, output의 확률 분포가 완만해져서 CrossEntropyLoss는 크게 보일 수 있다.\n",
    "     - CutMix는 일부 영역을 잘라서 붙이므로 좀 더 확실히 구분될 수 있는 특징을 기억할 것으로 생각됨.(MixUp보다 결정 경계가 덜 완만할 것으로 생각되는 이유.)\n",
    "     - CutMix는 정답과 상관없는 영역을 잘라서 붙일 수도 있으므로 노이즈가 더 많이 섞일 것으로 예상됨.\n",
    "\n",
    "**8. 아쉬운 점**\n",
    "- 생각보다 학습 시간이 오래걸려서 Epoch를 더 길게 보지 못한점이 아쉽다. Epoch를 더 길게 보면 예상했던 결과를 볼 수 있을것 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22950f1a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "case1_study",
   "language": "python",
   "name": "case1_study"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
